{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67939e79",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here I show how I process and systematically clean my data sets so that I can use them in subsequent analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea661e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version:  3.10.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib. pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "print('Matplotlib version: ', mpl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039918fe",
   "metadata": {},
   "source": [
    "Data cleaning of df_1 (1_maven_fuzzy_factory_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4b5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\1_maven_fuzzy_factory_data_dictionary.csv\")\n",
    "df_2 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\2_order_item_refunds.csv\")\n",
    "df_3 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\3_order_items.csv\")\n",
    "df_4 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\4_orders.csv\")\n",
    "df_5 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\5_products.csv\")\n",
    "df_6 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\6_website_pageviews.csv\")\n",
    "df_7 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\7_website_sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f610b831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       order_item_refund_id           created_at  order_item_id  order_id  \\\n",
       "0                        1  2012-04-06 11:32:43             57        57   \n",
       "1                        2  2012-04-13 01:09:43             74        74   \n",
       "2                        3  2012-04-15 07:03:48             71        71   \n",
       "3                        4  2012-04-17 20:00:37            118       118   \n",
       "4                        5  2012-04-22 20:53:49            116       116   \n",
       "...                    ...                  ...            ...       ...   \n",
       "1726                  1727  2015-03-30 09:37:23          39950     32255   \n",
       "1727                  1728  2015-03-30 21:33:51          39671     32049   \n",
       "1728                  1729  2015-03-31 19:59:48          39729     32090   \n",
       "1729                  1730  2015-04-01 03:54:48          39717     32079   \n",
       "1730                  1731  2015-04-01 18:11:08          39947     32252   \n",
       "\n",
       "      refund_amount_usd  \n",
       "0                 49.99  \n",
       "1                 49.99  \n",
       "2                 49.99  \n",
       "3                 49.99  \n",
       "4                 49.99  \n",
       "...                 ...  \n",
       "1726              59.99  \n",
       "1727              49.99  \n",
       "1728              49.99  \n",
       "1729              59.99  \n",
       "1730              45.99  \n",
       "\n",
       "[1731 rows x 5 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "order_item_refund_id:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "created_at:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "order_item_id:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "order_id:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "refund_amount_usd:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      " \n",
      "All values seem fine now!\n",
      " \n",
      "Cleaning complete: 1731 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:44: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:44: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\4244303580.py:44: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  os.makedirs('C:\\Projekt_Ordner\\Business_Analysis\\Data', exist_ok=True)\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\4244303580.py:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  df_2_refunds.to_csv('C:\\Projekt_Ordner\\Business_Analysis\\Data\\df_2_refunds.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "# Create copy of the data frame\n",
    "\n",
    "df_2_refunds = df_2.copy()\n",
    "\n",
    "#Remove Duplicates\n",
    "\n",
    "df_2_refunds = df_2_refunds.drop_duplicates()\n",
    "\n",
    "\n",
    "# Replace missing values with mean value\n",
    "\n",
    "numeric_cols = df_2_refunds.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df_2_refunds[col].isnull().sum() > 0:\n",
    "        median_val = df_2_refunds[col].median()\n",
    "        df_2_refunds[col].fillna(median_val, inplace=True)\n",
    "        print(f\"{col} (numeric): Filled {df_2_refunds[col].isnull().sum()} with median ({median_val:.2f})\")\n",
    "\n",
    "\n",
    "# Count missing values in each column\n",
    "\n",
    "missing_data = df_2_refunds.isnull()\n",
    "\n",
    "for column in df_2_refunds.columns:\n",
    "    total_rows = len(df_2_refunds)\n",
    "    missing_count = missing_data[column].sum()  # True (missing)\n",
    "    present_count = total_rows - missing_count   # False (there)\n",
    "    missing_pct = (missing_count / total_rows) * 100\n",
    "    \n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"  Missing:  {missing_count} ({missing_pct:.2f}%)\")\n",
    "    print(f\"  Present:  {present_count} ({100-missing_pct:.2f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "# We dont have categroic variables in df_2\n",
    "\n",
    "print (\" \")\n",
    "print(\"All values seem fine now!\")\n",
    "print(\" \")\n",
    "\n",
    "#Save it\n",
    "\n",
    "os.makedirs('C:\\Projekt_Ordner\\Business_Analysis\\Data', exist_ok=True)  #\"exist_ok=True\" Important: If the folder already exists, there will be NO error.\n",
    "df_2_refunds.to_csv('C:\\Projekt_Ordner\\Business_Analysis\\Data\\df_2_refunds.csv', index=False)\n",
    "\n",
    "print(f\"Cleaning complete: {len(df_2_refunds)} saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a34090",
   "metadata": {},
   "source": [
    "This was an example of how to clean on single data set, in this case a .csv file. \n",
    "Now I will automate this for the rest of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f92845f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1_maven_fuzzy_factory_data_dictionary.csv\n",
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\1_maven_fuzzy_factory_data_dictionary_clean.csv\n",
      "\n",
      "Processing: 2_order_item_refunds.csv\n",
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\2_order_item_refunds_clean.csv\n",
      "\n",
      "Processing: 3_order_items.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\2227124393.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\2227124393.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\3_order_items_clean.csv\n",
      "\n",
      "Processing: 4_orders.csv\n",
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\4_orders_clean.csv\n",
      "\n",
      "Processing: 5_products.csv\n",
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\5_products_clean.csv\n",
      "\n",
      "Processing: 6_website_pageviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\2227124393.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\2227124393.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\2227124393.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\6_website_pageviews_clean.csv\n",
      "\n",
      "Processing: 7_website_sessions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\2227124393.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data\\7_website_sessions_clean.csv\n",
      "\n",
      "All files cleaned and saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def complete_auto_cleaning(df):  #I define a function to clean the data in one step\n",
    "    \"\"\"Clean data: remove duplicates/replace missing data with mean value\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remove Duplicates\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "    # Replace missing data with mean\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns  #identifies the numeric columns\n",
    "    for col in numeric_cols:                                             #\n",
    "        df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "    #Future possibilities: \n",
    "    #Drop columns with >70% missing\n",
    "    # threshold = 0.7\n",
    "    # for col in df_clean.columns:\n",
    "    #     if df_clean[col].isnull().sum() / len(df_clean) > threshold:\n",
    "    #         df_clean.drop(columns=[col], inplace=True)\n",
    "        \n",
    "    #Mode\n",
    "    # categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
    "    # for col in categorical_cols:\n",
    "    #     if len(df_clean[col].mode()) > 0:\n",
    "    #         df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "    \n",
    "    #Clean text\n",
    "    # for col in categorical_cols:\n",
    "    #     df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "    \n",
    "    #Datetime\n",
    "    # date_cols = [col for col in df_clean.columns if 'date' in col.lower()]\n",
    "    # for col in date_cols:\n",
    "    #     df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')'\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "input_folder = r'C:\\Projekt_Ordner\\Business_Analysis\\Data'\n",
    "output_folder = r'C:\\Projekt_Ordner\\Business_Analysis\\Data\\Cleaned_Data' #r' for \"raw string\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True) #\"exist_ok=True\" Important: If the folder already exists, there will be NO error.\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')] #Finding all .csv files\n",
    "\n",
    "for file in csv_files:\n",
    "    print(f\"Processing: {file}\")\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(input_folder, file))\n",
    "    df_clean = complete_auto_cleaning(df)\n",
    "    \n",
    "    # Saving\n",
    "    output_path = os.path.join(output_folder, file.replace('.csv', '_clean.csv')) \n",
    "    df_clean.to_csv(output_path, index=False)\n",
    "    print(f\"Saved to: {output_path}\\n\")\n",
    "\n",
    "print(\"All files cleaned and saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
