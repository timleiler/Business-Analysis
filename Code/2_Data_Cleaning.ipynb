{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67939e79",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here I show how I process and systematically clean my data sets so that I can use them in subsequent analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea661e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version:  3.10.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib. pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "print('Matplotlib version: ', mpl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039918fe",
   "metadata": {},
   "source": [
    "Data cleaning of df_1 (1_maven_fuzzy_factory_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4b5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\1_maven_fuzzy_factory_data_dictionary.csv\")\n",
    "df_2 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\2_order_item_refunds.csv\")\n",
    "df_3 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\3_order_items.csv\")\n",
    "df_4 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\4_orders.csv\")\n",
    "df_5 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\5_products.csv\")\n",
    "df_6 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\6_website_pageviews.csv\")\n",
    "df_7 = pd.read_csv(r\"C:\\Projekt_Ordner\\Business_Analysis\\Data\\7_website_sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f610b831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       order_item_refund_id           created_at  order_item_id  order_id  \\\n",
       "0                        1  2012-04-06 11:32:43             57        57   \n",
       "1                        2  2012-04-13 01:09:43             74        74   \n",
       "2                        3  2012-04-15 07:03:48             71        71   \n",
       "3                        4  2012-04-17 20:00:37            118       118   \n",
       "4                        5  2012-04-22 20:53:49            116       116   \n",
       "...                    ...                  ...            ...       ...   \n",
       "1726                  1727  2015-03-30 09:37:23          39950     32255   \n",
       "1727                  1728  2015-03-30 21:33:51          39671     32049   \n",
       "1728                  1729  2015-03-31 19:59:48          39729     32090   \n",
       "1729                  1730  2015-04-01 03:54:48          39717     32079   \n",
       "1730                  1731  2015-04-01 18:11:08          39947     32252   \n",
       "\n",
       "      refund_amount_usd  \n",
       "0                 49.99  \n",
       "1                 49.99  \n",
       "2                 49.99  \n",
       "3                 49.99  \n",
       "4                 49.99  \n",
       "...                 ...  \n",
       "1726              59.99  \n",
       "1727              49.99  \n",
       "1728              49.99  \n",
       "1729              59.99  \n",
       "1730              45.99  \n",
       "\n",
       "[1731 rows x 5 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d783a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "order_item_refund_id:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "created_at:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "order_item_id:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "order_id:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      "\n",
      "refund_amount_usd:\n",
      "  Missing:  0 (0.00%)\n",
      "  Present:  1731 (100.00%)\n",
      " \n",
      "All values seem fine now!\n",
      " \n",
      "Cleaning complete: 1731 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:44: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:44: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\4244303580.py:44: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  os.makedirs('C:\\Projekt_Ordner\\Business_Analysis\\Data', exist_ok=True)\n",
      "C:\\Users\\T1M\\AppData\\Local\\Temp\\ipykernel_24488\\4244303580.py:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  df_2_refunds.to_csv('C:\\Projekt_Ordner\\Business_Analysis\\Data\\df_2_refunds.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "# Create copy of the data frame\n",
    "\n",
    "df_2_refunds = df_2.copy()\n",
    "\n",
    "#Remove Duplicates\n",
    "\n",
    "df_2_refunds = df_2_refunds.drop_duplicates()\n",
    "\n",
    "\n",
    "# Replace missing values with mean value\n",
    "\n",
    "numeric_cols = df_2_refunds.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df_2_refunds[col].isnull().sum() > 0:\n",
    "        median_val = df_2_refunds[col].median()\n",
    "        df_2_refunds[col].fillna(median_val, inplace=True)\n",
    "        print(f\"{col} (numeric): Filled {df_2_refunds[col].isnull().sum()} with median ({median_val:.2f})\")\n",
    "\n",
    "\n",
    "# Count missing values in each column\n",
    "\n",
    "missing_data = df_2_refunds.isnull()\n",
    "\n",
    "for column in df_2_refunds.columns:\n",
    "    total_rows = len(df_2_refunds)\n",
    "    missing_count = missing_data[column].sum()  # True (missing)\n",
    "    present_count = total_rows - missing_count   # False (there)\n",
    "    missing_pct = (missing_count / total_rows) * 100\n",
    "    \n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"  Missing:  {missing_count} ({missing_pct:.2f}%)\")\n",
    "    print(f\"  Present:  {present_count} ({100-missing_pct:.2f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "# We dont have categroic variables in df_2\n",
    "\n",
    "print (\" \")\n",
    "print(\"All values seem fine now!\")\n",
    "print(\" \")\n",
    "\n",
    "#Save it\n",
    "\n",
    "os.makedirs('C:\\Projekt_Ordner\\Business_Analysis\\Data', exist_ok=True)\n",
    "df_2_refunds.to_csv('C:\\Projekt_Ordner\\Business_Analysis\\Data\\df_2_refunds.csv', index=False)\n",
    "\n",
    "print(f\"Cleaning complete: {len(df_2_refunds)} saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a34090",
   "metadata": {},
   "source": [
    "This was an example of how to clean on single data set, in this case a .csv file. \n",
    "Now I will automate this for the rest of the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92845f8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
